{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0ed385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import joblib\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification, Trainer, TrainingArguments\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "DATA_DIR = \"data\"\n",
    "MODEL_DIR = \"models\"\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "SUPPORTED_IMG_EXT = {\".png\", \".jpg\", \".jpeg\", \".tif\", \".tiff\", \".bmp\"}\n",
    "\n",
    "def ocr_image(img: Image.Image, lang=\"eng+fra\") -> str:\n",
    "    g = img.convert(\"L\")\n",
    "    return pytesseract.image_to_string(g, lang=lang) or \"\"\n",
    "\n",
    "def ocr_file(path: str) -> str:\n",
    "    path_low = path.lower()\n",
    "    if path_low.endswith(\".pdf\"):\n",
    "        pages = convert_from_path(path, dpi=200, first_page=1, last_page=3)\n",
    "        texts = [ocr_image(p) for p in pages]\n",
    "        return \"\\n\".join(texts)\n",
    "    else:\n",
    "        return ocr_image(Image.open(path))\n",
    "\n",
    "rows = []\n",
    "labels_map = {\"identity\":0, \"invoice\":1, \"mail\":2, \"other\":3}\n",
    "\n",
    "for label in labels_map:\n",
    "    folder = os.path.join(DATA_DIR, label)\n",
    "    if not os.path.isdir(folder):\n",
    "        continue\n",
    "    for ext in list(SUPPORTED_IMG_EXT) + [\".pdf\"]:\n",
    "        for f in glob.glob(os.path.join(folder, f\"**/*{ext}\"), recursive=True):\n",
    "            try:\n",
    "                text = ocr_file(f)\n",
    "                rows.append({\"text\": text, \"label\": labels_map[label]})\n",
    "            except Exception as e:\n",
    "                print(\"[WARN] OCR failed:\", f, e)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df[\"text\"], df[\"label\"], test_size=0.2, random_state=42, stratify=df[\"label\"])\n",
    "\n",
    "# Hugging Face Dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=512):\n",
    "        self.encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=max_len)\n",
    "        self.labels = labels.tolist()\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "tokenizer = CamembertTokenizer.from_pretrained(\"camembert-base\")\n",
    "\n",
    "train_dataset = TextDataset(X_train, y_train, tokenizer)\n",
    "val_dataset = TextDataset(X_val, y_val, tokenizer)\n",
    "\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=4)\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=MODEL_DIR,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=2,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=2,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "\n",
    "model.save_pretrained(MODEL_DIR)\n",
    "tokenizer.save_pretrained(MODEL_DIR)\n",
    "print(\"Saved CamemBERT model to\", MODEL_DIR)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
